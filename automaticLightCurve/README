Welcome to the Fermi/LAT flare alert pipeline at the Landessternwarte !

This pipeline can be used to quickly generate short- or long-term Fermi/LAT light curves. It relies on the Fermi/LAT aperture photometric analysis (cf. e.g. http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/aperture_photometry.html), which basically assumes that the data set, within 1 degree around the source, is background-free.

Thus, it is meant to have a rough feeling about the variability of a source, but is absolutely not reliable enough to obtain publication-ready data.

The pipeline can be used to assess the variability of a particular source, using the script 'automaticLightCurve.py', or to process all the sources included in the "master" list of sources 'listSources.txt' using the script 'processAllSources.py'. Basically, 'processAllSources.py' just calls 'automaticLightCurve.py' for each entry in the list of sources.


PRINCIPLE:
==========

The pipeline generates light curves from Fermi/LAT data, using an unusually small "region of interest" of 1 degree, in which the data set is assumed to be background-free.

For a given source, it first looks whether the source of interest has a counterpart in the 2FGL catalogue. This is done by scanning the "master" list of sources 'listSources.txt', which includes a column with 2FGL name, if any, for a given source.

If the source is included in the 2FGL catalogue, the scripts use the FITS catalogue file 'gll_psc_v07.fit' to generate an XML model file using the script 'make2FGLxml.py'. It means that we assume that the spectral parameters of our source of interest is as per the 2FGL catalogue. This is of course not valid for a source with a strong spectral variability.

If the source is not included in the 2FGL catalogue, the pipeline assumes that the spectrum of the source is a power-law with a photon index Gamma=-2.5. This value is encoded in the file 'automaticLightCurve.py' in the function 'processSrc'.

By default, the script 'processAllSources.py' uses the list of sources 'listSources.txt'. However, a user can give another list of sources as input, albeit that the format should be the same.

On the machine 'hess-lsw', the script 'processAllSources.py' calls the shell command 'parallel', to process 8 different sources in parallel, in a "nice" way. It means that if other processes (such as an H.E.S.S. analysis) are running on 'hess-lsw', the pipeline will not overload the machine.

If the last flux point of a source si above the trigger threshold, a mail will be generated and sent, with a PNG figure of the light curve in attachement.

The trigger threshold is set to 1.e-6 ph cm^-2 s^-1 by default. However, this threshold can be individually set for each source in the file 'listSources.txt'.



DOWNLOAD:
=========

To download the pipeline, type in a terminal:

> svn co svn+ssh://fermi@hess-lsw/home/fermi/svn/automaticLightCurve

The password is the first name of the famous eponymous physicist, in lower case :-)


The pipeline includes:

- automaticLightCurve.py	to process a single source.
- processAllSources.py		to process a bunch of sources, which actually calls the script 'automaticLightCurve.py' for each individual source.
- listSources.txt		the master list of sources, including ATOM sources, TeVCat sources (mainly AGN only, for the moment), and others.
- gll_psc_v07.fit		the last official release of the 2FGL catalogue, in FITS format.
- make2FGLxml.py		user-contributed Fermi Science Tools script, which is used to generate an XML model file from the FITS 2FGL catalogue file.
- TODO				a list of things to be improved.
- README			this file.

Help can be found on the two individual scripts, by typing:

> ./automaticLightCurve.py -h
> ./processAllSources.py -h


The pipeline depends on the Fermi Science Tools, and it is assumed that you have a local installation of this software on your machine (for more details, see http://fermi.gsfc.nasa.gov/ssc/data/analysis/software/). In more details, the two Python scripts 'automaticLightCurve.py' and 'processAllSources.py' should be able to find the 'gt_apps' Python modules provided in the Fermi Science Tools (be careful to have your shell variable $PYTHONPATH up-to-date !).

The pipeline depends on a few (big) files, which are automatically re-created every day on the LSW server 'hess-lsw':

- /data/fermi/allsky/allsky_30MeV_300GeV_diffuse_filtered.fits	   	      event files for the whole sky, for the whole mission (kept up-to-date from the NASA servers every day).
- /data/fermi/allsky/allsky_last70days_30MeV_300GeV_diffuse_filtered.fits     event files for the whole sky, for the last 70 days. Useful to speed up the light curve generation process. 
- /data/fermi/allsky/allsky_SC00.fits					      last "spacecraft" file, which includes the telemetry of the Fermi spacecraft (kept up-to-date from the NASA servers every day).




Author: J.-P. Lenain <mailto:jean-philippe.lenain@lsw.uni-heidelberg.de>
Last modification: $Id$
